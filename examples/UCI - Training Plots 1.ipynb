{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import abstract_gradient_training as agt\n",
    "from models.fully_connected import FullyConnected\n",
    "from datasets.uci import get_dataloaders\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook config\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('poster')\n",
    "\n",
    "figsize = (5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the training parameters\n",
    "batchsize = 10000\n",
    "nominal_config = agt.AGTConfig(\n",
    "    fragsize=10000,\n",
    "    learning_rate=0.05,\n",
    "    lr_decay=1.0,\n",
    "    n_epochs=1,\n",
    "    device=\"cuda:1\",\n",
    "    forward_bound=\"interval\",\n",
    "    backward_bound=\"interval\",\n",
    "    loss=\"mse\",\n",
    "    log_level=\"INFO\",\n",
    "    early_stopping=False,\n",
    "    metadata=f\"uci, batchsize={batchsize}\",\n",
    "    bound_kwargs={\"interval_matmul\": \"exact\"}\n",
    ")\n",
    "\n",
    "# get the data and nn model\n",
    "torch.manual_seed(0)\n",
    "dl_train, dl_test = get_dataloaders(batchsize, batchsize, \"houseelectric\")\n",
    "model = FullyConnected(11, 1, 50, 1)  # network with 1 hidden layer of 64 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sweep(config, sweep_parameter, sweep_values):\n",
    "    config = copy.deepcopy(config)\n",
    "\n",
    "    for val in sweep_values:\n",
    "        config.__setattr__(sweep_parameter, val)\n",
    "        conf_hash = config.hash()\n",
    "        fname = f\".results/uci_{conf_hash}.pt\"\n",
    "        if os.path.isfile(fname):\n",
    "            continue\n",
    "        training = []\n",
    "        def log(*args):\n",
    "            training.append(copy.deepcopy(args))\n",
    "        config.callback = log\n",
    "                \n",
    "        torch.manual_seed(0)\n",
    "        dl_train, dl_test = get_dataloaders(batchsize, batchsize, \"houseelectric\")\n",
    "        param_l, param_n, param_u = agt.poison_certified_training(model, config, dl_train, dl_test)\n",
    "        worst = [t[0][0] for t in training]\n",
    "        nominal = [t[0][1] for t in training]\n",
    "        best = [t[0][2] for t in training]\n",
    "        torch.save((worst, nominal, best), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(config, sweep_parameter, sweep_values, label, ax=None):\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots(figsize=figsize)\n",
    "        save = True\n",
    "        ax.set_ylabel(\"Mean Squared Error\")\n",
    "        ax.set_ylim(0, 0.5)\n",
    "        ax.set_xlabel(\"Training Iteration\")\n",
    "    else: \n",
    "        save = False\n",
    "    config = copy.deepcopy(config)\n",
    "\n",
    "    vals = []\n",
    "    mse = []\n",
    "    colors = list(iter(palette))[:len(sweep_values)]\n",
    "    colors = colors + colors [::-1]\n",
    "    \n",
    "    lines = []\n",
    "\n",
    "    for val in sweep_values:\n",
    "        config.__setattr__(sweep_parameter, val)\n",
    "        conf_hash = config.hash()\n",
    "        fname = f\".results/uci_{conf_hash}.pt\"\n",
    "        worst, nominal, best = torch.load(fname)\n",
    "        lines.extend([worst, best])\n",
    "    lines.append(nominal)\n",
    "    x = np.arange(len(lines[0]))\n",
    "    lines.sort(key=lambda x: x[-1])\n",
    "    for i in range(len(lines) - 1):\n",
    "        ax.fill_between(x, lines[i], lines[i+1], color=\"w\", alpha=1.0, lw=0)\n",
    "        if i < len(sweep_values):\n",
    "            ax.fill_between(x, lines[i], lines[i+1], color=colors[i], alpha=0.6, label=f'${label}={sweep_values[i]}$', lw=0)\n",
    "        else:\n",
    "            ax.fill_between(x, lines[i], lines[i+1], color=colors[i], alpha=0.6, lw=0)\n",
    "    # ax.fill_between(range(len(nominal)), worst, best, color=color, alpha=1.0, label=f'${label}={config[sweep_parameter]}$')\n",
    "    ax.plot(nominal, color=nominal_color, lw=2)\n",
    "    ax.legend(loc=\"upper right\", fontsize=\"small\")\n",
    "    return vals, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context=\"poster\", style=\"whitegrid\", font_scale=1.1)\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 3.8), sharey=True, layout='constrained')\n",
    "axs[0].set_ylim(-0.02, 0.5)\n",
    "# [ax.set_box_aspect(1) for ax in axs]\n",
    "[ax.set_xlim(-5, 145) for ax in axs]\n",
    "palette = sns.color_palette(palette=\"Dark2\", n_colors=8)\n",
    "nominal_color = next(iter(sns.color_palette(palette=\"Set1\", n_colors=4)))\n",
    "\n",
    "# palette = sns.color_palette(palette=\"Greens\", n_colors=4)\n",
    "# palette = sns.color_palette(palette=\"Set1\", n_colors=4)\n",
    "\n",
    "conf = copy.deepcopy(nominal_config)\n",
    "conf.epsilon = 0.01\n",
    "ks = [10000, 5000, 1000]\n",
    "run_sweep(conf, \"k_poison\", ks)\n",
    "plot_training(conf, \"k_poison\", ks, \"n\", axs[0])\n",
    "axs[0].set_title(\"Feature poisoning $(\\epsilon=0.01)$\", pad=15)\n",
    "\n",
    "conf = copy.deepcopy(nominal_config)\n",
    "conf.k_poison = 1000\n",
    "epsilons = [0.15, 0.1, 0.05]\n",
    "run_sweep(conf, \"epsilon\", epsilons)\n",
    "plot_training(conf, \"epsilon\", epsilons, \"\\epsilon\", axs[1])\n",
    "axs[1].set_title(\"Feature poisoning $(n=1000)$\", pad=15)\n",
    "\n",
    "conf = copy.deepcopy(nominal_config)\n",
    "conf.label_epsilon = 0.05\n",
    "ks = [10000, 5000, 1000]\n",
    "run_sweep(conf, \"label_k_poison\", ks)\n",
    "plot_training(conf, \"label_k_poison\", ks, \"m\", axs[2])\n",
    "axs[2].set_title(r\"Label poisoning $(\\nu=0.05)$\", pad=15)\n",
    "\n",
    "conf = copy.deepcopy(nominal_config)\n",
    "conf.label_k_poison = 1000\n",
    "epsilons = [0.75, 0.5, 0.25]\n",
    "run_sweep(conf, \"label_epsilon\", epsilons)\n",
    "plot_training(conf, \"label_epsilon\", epsilons, r\"\\nu\", axs[3])\n",
    "axs[3].set_title(\"Label poisoning $(m=1000)$\", pad=15)\n",
    "\n",
    "fig.supylabel(\"MSE + Bounds\", fontsize=\"x-large\")\n",
    "# fig.supxlabel(\"Training Iteration\", y=-0.1, fontsize=\"x-large\")\n",
    "plt.savefig(f\".figures/uci_training_1.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
