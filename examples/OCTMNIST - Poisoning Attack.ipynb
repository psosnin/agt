{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Certified poisoning robust training on the OCT-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import abstract_gradient_training as agt\n",
    "from abstract_gradient_training import AGTConfig\n",
    "from abstract_gradient_training import model_utils\n",
    "from labellines import *\n",
    "\n",
    "from models.deepmind import DeepMindSmall \n",
    "from datasets import oct_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \".results/\"\n",
    "seed = 3\n",
    "notebook_id = f\"oct_sweep_poison_{seed}\"\n",
    "model_path = \"../models/medmnist_pretrained.ckpt\"\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the nominal config, model and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class poisoned_dataloader:\n",
    "    def __init__(self, dataloader, label_k_poison):\n",
    "        self.dataloader = dataloader\n",
    "        self.label_k_poison = label_k_poison\n",
    "        self.poisoned_dataloader = self._poison_dataloader()\n",
    "    \n",
    "    def _poison_dataloader(self):\n",
    "        poisoned_dataloader = []\n",
    "        for x, y in self.dataloader:\n",
    "            # randomly choose a subset of the data to poison\n",
    "            idx = torch.randperm(len(y))[:self.label_k_poison]\n",
    "            y[idx] = 1 - y[idx]\n",
    "            poisoned_dataloader.append((x, y))\n",
    "        return poisoned_dataloader\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.poisoned_dataloader)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.poisoned_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "clean_batchsize = 3000\n",
    "drusen_batchsize = 3000\n",
    "test_batchsize = 1000\n",
    "\n",
    "nominal_config = AGTConfig(\n",
    "    fragsize=2000,\n",
    "    learning_rate=0.05,\n",
    "    label_k_poison=1000,\n",
    "    n_epochs=2,\n",
    "    forward_bound=\"interval\",\n",
    "    device=\"cuda:0\",\n",
    "    backward_bound=\"interval\",\n",
    "    loss=\"binary_cross_entropy\",\n",
    "    log_level=\"DEBUG\",\n",
    "    lr_decay=5.0,\n",
    "    lr_min=0.001,\n",
    "    early_stopping=False,\n",
    ")\n",
    "\n",
    "# get dataloaders\n",
    "dl_clean, dl_test_clean = oct_mnist.get_dataloaders(clean_batchsize, test_batchsize, exclude_classes=[2])\n",
    "dl_drusen, dl_test_drusen = oct_mnist.get_dataloaders(drusen_batchsize, test_batchsize, exclude_classes=[0, 1, 3])\n",
    "_, dl_test_all = oct_mnist.get_dataloaders(clean_batchsize, test_batchsize)\n",
    "\n",
    "# get the \"DeepMindSmall\" model, pretrained on the MedMNIST dataset (without class 2, Drusen)\n",
    "model = DeepMindSmall(1, 1)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.to(nominal_config.device)\n",
    "\n",
    "conv_layers = model[0:5]\n",
    "linear_layers = model[5:-1]\n",
    "conv_transform = model_utils.get_conv_model_transform(conv_layers)\n",
    "param_l, param_n, param_u = model_utils.get_parameters(linear_layers)\n",
    "\n",
    "# evaluate the pre-trained model\n",
    "param_l, param_n, param_u = model_utils.get_parameters(linear_layers)\n",
    "drusen_acc = agt.test_metrics.test_accuracy(\n",
    "    param_l, param_n, param_u, *next(iter(dl_test_drusen)), transform=conv_transform\n",
    ")\n",
    "pretrained_acc_backdoor = agt.test_metrics.test_accuracy(\n",
    "    param_l, param_n, param_u, *next(iter(dl_test_drusen)), transform=conv_transform, epsilon=0.001\n",
    ")\n",
    "pretrained_acc = drusen_acc[1]\n",
    "clean_acc = agt.test_metrics.test_accuracy(\n",
    "    param_l, param_n, param_u, *next(iter(dl_test_clean)), transform=conv_transform\n",
    ")\n",
    "all_acc = agt.test_metrics.test_accuracy(param_l, param_n, param_u, *next(iter(dl_test_all)), transform=conv_transform)\n",
    "\n",
    "print(\"=========== Pre-trained model accuracy ===========\", file=sys.stderr)\n",
    "print(f\"Class 2 (Drusen) : nominal = {drusen_acc[1]:.2g}\", file=sys.stderr)\n",
    "print(f\"Classes 0, 1, 3  : nominal = {clean_acc[1]:.2g}\", file=sys.stderr)\n",
    "print(f\"All Classes      : nominal = {all_acc[1]:.2g}\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tune the model using abstract gradient training (keeping the convolutional layers fixed)\n",
    "conf = copy.deepcopy(nominal_config)\n",
    "param_l, param_n, param_u = agt.poison_certified_training(\n",
    "    linear_layers, conf, dl_drusen, dl_test_drusen, dl_clean=dl_clean, transform=conv_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tune the model using abstract gradient training (keeping the convolutional layers fixed)\n",
    "conf = copy.deepcopy(nominal_config)\n",
    "conf.label_k_poison = 100\n",
    "dl_drusen_poisoned = poisoned_dataloader(dl_drusen, conf.label_k_poison)\n",
    "param_l, param_n, param_u = agt.poison_certified_training(\n",
    "    linear_layers, conf, dl_drusen_poisoned, dl_test_drusen, dl_clean=dl_clean, transform=conv_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cert_accs = []\n",
    "poison_accs = []\n",
    "\n",
    "for k in range(0, 1001, 50):\n",
    "    conf = copy.deepcopy(nominal_config)\n",
    "    conf.label_k_poison = k\n",
    "    # clean run\n",
    "    torch.manual_seed(seed)\n",
    "    param_l, param_n, param_u = agt.poison_certified_training(\n",
    "        linear_layers, conf, dl_drusen, dl_test_drusen, dl_clean=dl_clean, transform=conv_transform\n",
    "    )\n",
    "    cert_accs.append(\n",
    "        agt.test_metrics.test_accuracy(\n",
    "            param_l, param_n, param_u, *next(iter(dl_test_drusen)), transform=conv_transform\n",
    "        )[0]\n",
    "    )\n",
    "\n",
    "    # poisoned run\n",
    "    torch.manual_seed(seed)\n",
    "    dl_drusen_poisoned = poisoned_dataloader(dl_drusen, conf.label_k_poison)\n",
    "    param_l, param_n, param_u = agt.poison_certified_training(\n",
    "        linear_layers, conf, dl_drusen_poisoned, dl_test_drusen, dl_clean=dl_clean, transform=conv_transform\n",
    "    )\n",
    "    poison_accs.append(\n",
    "        agt.test_metrics.test_accuracy(\n",
    "            param_l,\n",
    "            param_n,\n",
    "            param_u,\n",
    "            *next(iter(dl_test_drusen)),\n",
    "            transform=conv_transform\n",
    "        )[1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(palette=\"Dark2\", n_colors=12)\n",
    "lb_color = list(iter(sns.color_palette(palette=\"deep\")))[-1]\n",
    "ub_color = list(iter(sns.color_palette(palette=\"deep\")))[-2]\n",
    "\n",
    "sns.set_theme(context=\"poster\", style=\"whitegrid\", font_scale=1.5)\n",
    "mpl.rcParams[\"mathtext.fontset\"] = \"stix\"\n",
    "mpl.rcParams[\"font.family\"] = \"STIXGeneral\"\n",
    "labelsize = 22\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    1,\n",
    "    1,\n",
    "    figsize=(10, 8),\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "# ax.set_title(\"Random Label Flipping Attack \")\n",
    "\n",
    "colors = iter(palette)\n",
    "nom_accs = [cert_accs[0] for _ in cert_accs]\n",
    "poison_accs[0] = cert_accs[0]\n",
    "color = next(colors)\n",
    "ax.plot(range(0, 1001, 50), cert_accs, color=color, label=\"Certified Accuracy\")\n",
    "ax.plot(range(0, 1001, 50), nom_accs, color=color, linestyle=\"--\", label=\"Clean Accuracy\")\n",
    "color = next(colors)\n",
    "ax.plot(range(0, 1001, 50), poison_accs, color=color, label=\"Poisoned Accuracy\", linestyle=\":\")\n",
    "\n",
    "ax.set_ylabel(\"Accuracy\", fontsize=\"x-large\")\n",
    "ax.set_xlabel(\"Attack Size ($m$)\", fontsize=\"x-large\")\n",
    "ax.legend(loc=\"lower left\")\n",
    "\n",
    "plt.savefig(f\".figures/oct_mnist_rand_flips.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
