{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Certified poisoning-robust training on the OCT-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import abstract_gradient_training as agt\n",
    "from abstract_gradient_training import AGTConfig\n",
    "from abstract_gradient_training import model_utils\n",
    "from abstract_gradient_training import test_metrics\n",
    "from labellines import labelLines\n",
    "\n",
    "from models.deepmind import DeepMindSmall \n",
    "from datasets import oct_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \".results/\"\n",
    "seed = 3\n",
    "notebook_id = f\"oct_sweep_poison_{seed}\"\n",
    "model_path = \"models/medmnist_pretrained.ckpt\"\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the nominal config, model and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_batchsize = 3000\n",
    "drusen_batchsize = 3000\n",
    "test_batchsize = 1000\n",
    "\n",
    "nominal_config = AGTConfig(\n",
    "    fragsize=2000,\n",
    "    learning_rate=0.05,\n",
    "    n_epochs=2,\n",
    "    forward_bound=\"interval\",\n",
    "    device=\"cuda:0\",\n",
    "    backward_bound=\"interval\",\n",
    "    loss=\"binary_cross_entropy\",\n",
    "    log_level=\"DEBUG\",\n",
    "    lr_decay=5.0,\n",
    "    lr_min=0.001,\n",
    "    early_stopping=False,\n",
    ")\n",
    "\n",
    "\n",
    "# get the \"DeepMindSmall\" model, pretrained on the MedMNIST dataset (without class 2, Drusen)\n",
    "model = DeepMindSmall(1, 1)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.to(nominal_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstract_gradient_training.poisoning import poison_certified_training\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "conv_layers = model[0:5]\n",
    "linear_layers = model[5:-1]\n",
    "conv_transform = model_utils.get_conv_model_transform(conv_layers)\n",
    "param_l, param_n, param_u = model_utils.get_parameters(linear_layers)\n",
    "\n",
    "# get dataloaders\n",
    "dl_clean, dl_test_clean = oct_mnist.get_dataloaders(clean_batchsize, test_batchsize, exclude_classes=[2])\n",
    "dl_drusen, dl_test_drusen = oct_mnist.get_dataloaders(drusen_batchsize, test_batchsize, exclude_classes=[0, 1, 3])\n",
    "_, dl_test_all = oct_mnist.get_dataloaders(clean_batchsize, test_batchsize)\n",
    "\n",
    "# evaluate the pre-trained model\n",
    "param_l, param_n, param_u = model_utils.get_parameters(linear_layers)\n",
    "drusen_acc = agt.test_metrics.test_accuracy(\n",
    "    param_l, param_n, param_u, *next(iter(dl_test_drusen)), transform=conv_transform\n",
    ")\n",
    "pretrained_acc_backdoor = agt.test_metrics.test_accuracy(\n",
    "    param_l,\n",
    "    param_n,\n",
    "    param_u,\n",
    "    *next(iter(dl_test_drusen)),\n",
    "    transform=conv_transform,\n",
    "    epsilon=0.001,\n",
    ")\n",
    "print(pretrained_acc_backdoor)\n",
    "pretrained_acc = drusen_acc[1]\n",
    "clean_acc = agt.test_metrics.test_accuracy(\n",
    "    param_l, param_n, param_u, *next(iter(dl_test_clean)), transform=conv_transform\n",
    ")\n",
    "all_acc = agt.test_metrics.test_accuracy(param_l, param_n, param_u, *next(iter(dl_test_all)), transform=conv_transform)\n",
    "\n",
    "print(\"=========== Pre-trained model accuracy ===========\", file=sys.stderr)\n",
    "print(f\"Class 2 (Drusen) : nominal = {drusen_acc[1]:.2g}\", file=sys.stderr)\n",
    "print(f\"Classes 0, 1, 3  : nominal = {clean_acc[1]:.2g}\", file=sys.stderr)\n",
    "print(f\"All Classes      : nominal = {all_acc[1]:.2g}\", file=sys.stderr)\n",
    "\n",
    "drusen_acc_backdoor = agt.test_metrics.test_accuracy(\n",
    "    param_l,\n",
    "    param_n,\n",
    "    param_u,\n",
    "    *next(iter(dl_test_drusen)),\n",
    "    transform=conv_transform,\n",
    "    epsilon=0.001,\n",
    ")\n",
    "print(f\"Class 2 (Drusen) : backdoor = {drusen_acc_backdoor}\", file=sys.stderr)\n",
    "\n",
    "# fine-tune the model using abstract gradient training (keeping the convolutional layers fixed)\n",
    "conf = copy.deepcopy(nominal_config)\n",
    "conf.k_poison = 50\n",
    "conf.epsilon = 0.01\n",
    "param_l, param_n, param_u = poison_certified_training(\n",
    "    linear_layers, conf, dl_drusen, dl_test_drusen, dl_clean=dl_clean, transform=conv_transform\n",
    ")\n",
    "\n",
    "# evaluate the fine-tuned model\n",
    "drusen_acc = agt.test_metrics.test_accuracy(\n",
    "    param_l, param_n, param_u, *next(iter(dl_test_drusen)), transform=conv_transform\n",
    ")\n",
    "clean_acc = agt.test_metrics.test_accuracy(\n",
    "    param_l, param_n, param_u, *next(iter(dl_test_clean)), transform=conv_transform\n",
    ")\n",
    "all_acc = agt.test_metrics.test_accuracy(param_l, param_n, param_u, *next(iter(dl_test_all)), transform=conv_transform)\n",
    "\n",
    "print(\"=========== Fine-tuned model accuracy + bounds ===========\", file=sys.stderr)\n",
    "print(f\"Class 2 (Drusen) : nominal = {drusen_acc[1]:.2g}, certified bound = {drusen_acc[0]:.2g}\", file=sys.stderr)\n",
    "print(f\"Classes 0, 1, 3  : nominal = {clean_acc[1]:.2g}, certified bound = {clean_acc[0]:.2g}\", file=sys.stderr)\n",
    "print(f\"All Classes      : nominal = {all_acc[1]:.2g}, certified bound = {all_acc[0]:.2g}\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to perform the sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_config(config, backdoor=False):\n",
    "    \"\"\"If results for this configuration are already computed, load them from disk. Otherwise, run the certified\n",
    "    training using AGT, then save and return the results.\"\"\"\n",
    "    fname = f\"{results_dir}/{notebook_id}_{config.hash()}\"\n",
    "    if os.path.isfile(fname):  # run exists, so return the previous results\n",
    "        param_l, param_n, param_u = torch.load(fname)\n",
    "    else:\n",
    "        assert not (config.k_unlearn and config.k_private)\n",
    "        torch.manual_seed(seed)\n",
    "        if config.k_private:\n",
    "            param_l, param_n, param_u = agt.privacy_certified_training(\n",
    "                linear_layers, config, dl_drusen, dl_test_drusen, dl_public=dl_clean, transform=conv_transform\n",
    "            )\n",
    "        else:\n",
    "            param_l, param_n, param_u = agt.poison_certified_training(\n",
    "                linear_layers, config, dl_drusen, dl_test_drusen, dl_clean=dl_clean, transform=conv_transform\n",
    "            )\n",
    "        torch.save((param_l, param_n, param_u), fname)\n",
    "    # get nominal accuracy (on the Drusen class) and percent certified (on the entire test set)\n",
    "    test_eps = config.epsilon if backdoor else 0.0\n",
    "    accuracy = test_metrics.test_accuracy(\n",
    "        param_l,\n",
    "        param_n,\n",
    "        param_u,\n",
    "        *next(iter(dl_test_drusen)),\n",
    "        transform=conv_transform,\n",
    "        epsilon=test_eps,\n",
    "    )\n",
    "    del param_l, param_n, param_u\n",
    "    torch.cuda.empty_cache()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the sweep over different gamma and k values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments:\n",
    "\n",
    "1. Feature poisoning with bounded adversary\n",
    "2. Label flipping with bounded adversary\n",
    "3. Feature + label flipping with bounded adversary\n",
    "4. Feature + label poisoning with unbounded adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 1\n",
    "k_poisons = list(range(0, 601, 20))\n",
    "\n",
    "# k_poisons_1 = [0, 50, 100, 150, 200, 250, 300]\n",
    "# k_poisons_1 = [0, 150, 300, 500]\n",
    "epsilons_1 = [0.01, 0.02, 0.1]\n",
    "\n",
    "results_1 = {}\n",
    "\n",
    "config = copy.deepcopy(nominal_config)\n",
    "\n",
    "for epsilon in epsilons_1:\n",
    "    tmp_results = {}\n",
    "    for k_poison in k_poisons:\n",
    "        config.k_poison = k_poison\n",
    "        config.epsilon = epsilon\n",
    "        tmp_results[k_poison] = run_with_config(config)\n",
    "    results_1[epsilon] = tmp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 3\n",
    "# k_poisons_3 = [0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]\n",
    "# k_poisons_3 = [0, 500, 1000]\n",
    "results_3 = {}\n",
    "\n",
    "config = copy.deepcopy(nominal_config)\n",
    "\n",
    "for k_poison in k_poisons:\n",
    "    config.label_k_poison = k_poison\n",
    "    results_3[k_poison] = run_with_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 4\n",
    "\n",
    "# k_poisons_4 = [0, 50, 100, 150, 200, 250, 300]\n",
    "# k_poisons_4 = [0, 25, 50, 75, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "clip_gammas = [0.5, 1.0, 4.0]\n",
    "\n",
    "results_4 = {}\n",
    "\n",
    "config = copy.deepcopy(nominal_config)\n",
    "for clip_gamma in clip_gammas:\n",
    "    tmp_results = {}\n",
    "    for k_poison in k_poisons:\n",
    "        config.k_private = k_poison\n",
    "        config.clip_gamma = clip_gamma\n",
    "        tmp_results[k_poison] = run_with_config(config)\n",
    "    results_4[clip_gamma] = tmp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 5\n",
    "\n",
    "# k_poisons_5 = [0, 50, 100, 150, 200, 250, 300]\n",
    "# k_poisons_5 = [0, 50, 100, 150, 300, 350, 400, 450, 500]\n",
    "epsilons_1 = [0.003, 0.006, 0.009]\n",
    "\n",
    "results_5 = {}\n",
    "\n",
    "config = copy.deepcopy(nominal_config)\n",
    "\n",
    "for epsilon in epsilons_1:\n",
    "    tmp_results = {}\n",
    "    for k_poison in k_poisons:\n",
    "        config.k_poison = k_poison\n",
    "        config.epsilon = epsilon\n",
    "        tmp_results[k_poison] = run_with_config(config, backdoor=True)\n",
    "    results_5[epsilon] = tmp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(palette=\"Dark2\", n_colors=12)\n",
    "lb_color = list(iter(sns.color_palette(palette=\"deep\")))[-1]\n",
    "ub_color = list(iter(sns.color_palette(palette=\"deep\")))[-2]\n",
    "\n",
    "sns.set_theme(context=\"poster\", style=\"whitegrid\", font_scale=1.3)\n",
    "mpl.rcParams[\"mathtext.fontset\"] = \"stix\"\n",
    "mpl.rcParams[\"font.family\"] = \"STIXGeneral\"\n",
    "labelsize = 22\n",
    "\n",
    "def plot_experiment(results, ax, type=1, label=r\"\\epsilon\"):\n",
    "    if type == 1:\n",
    "        colors = iter(palette)\n",
    "        for epsilon, results in results.items():\n",
    "            nom_accs = [res[1] for res in results.values()]\n",
    "            cert_accs = [res[0] for res in results.values()]\n",
    "            k_poisons = list(results.keys())\n",
    "            color = next(colors)\n",
    "            if epsilon == 0.01:\n",
    "                ax.plot(k_poisons, nom_accs, linestyle=\"--\", color=color)\n",
    "            ax.plot(k_poisons, cert_accs, label=fr\"${label}={epsilon}$\", color=color)\n",
    "    elif type == 2:\n",
    "        colors = iter(palette)\n",
    "        nom_accs = [res[1] for res in results.values()]\n",
    "        k_poisons = list(results.keys())\n",
    "        cert_accs = [res[0] for res in results.values()]\n",
    "        color = next(colors)\n",
    "        ax.plot(k_poisons, nom_accs, color=color, linestyle=\"--\")\n",
    "        ax.plot(k_poisons, cert_accs, color=color)\n",
    "    elif type == 3:\n",
    "        colors = iter(palette)\n",
    "        for epsilon, results in results.items():\n",
    "            nom_accs = [res[1] for res in results.values()]\n",
    "            cert_accs = [res[0] for res in results.values()]\n",
    "            k_poisons = list(results.keys())\n",
    "            color = next(colors)\n",
    "            ax.plot(k_poisons, nom_accs, color=color, linestyle=\"--\")\n",
    "            ax.plot(k_poisons, cert_accs, label=fr\"${label}={epsilon}$\", color=color)\n",
    "    elif type == 4:\n",
    "        colors = iter(palette)\n",
    "        for epsilon, results in results.items():\n",
    "            cert_accs = [res[0] for res in results.values()]\n",
    "            nom_accs = [cert_accs[0] for res in results.values()]\n",
    "            k_poisons = list(results.keys())\n",
    "            color = next(colors)\n",
    "            ax.plot(k_poisons, nom_accs, color=color, linestyle=\"--\")\n",
    "            ax.plot(k_poisons, cert_accs, label=fr\"${label}={epsilon}$\", color=color)\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    1,\n",
    "    5,\n",
    "    figsize=(20, 15),\n",
    "    layout=\"constrained\",\n",
    "    width_ratios=[1, 1, 1, 0.01, 1],\n",
    "    sharey=False,\n",
    "    gridspec_kw={\"hspace\": 0.01, \"wspace\": 0.01},\n",
    ")\n",
    "[a.set_box_aspect(1) for a in ax]\n",
    "\n",
    "ax[3].set_visible(False)\n",
    "ax[0].set_title(\"Feature Poisoning\\n(Bounded Adversary)\", pad=15)\n",
    "ax[0].set_xlabel(\"Attack Size ($n$)\")\n",
    "plot_experiment(results_1, ax[0])\n",
    "labelLines(ax[0].get_lines(), align=False, drop_label=True, fontsize=labelsize, xvals=[500, 430, 320])\n",
    "\n",
    "# ax[1].set_title(\"Label Flipping\", pad=15)\n",
    "# ax[1].set_xlabel(\"$n=m$\")\n",
    "# plot_experiment(results_2, ax[1])\n",
    "# labelLines(ax[1].get_lines(), align=False, drop_label=True, fontsize=labelsize)\n",
    "\n",
    "ax[1].set_title(\"Label Poisoning\\n(Bounded Adversary)\", pad=15)\n",
    "ax[1].set_xlabel(\"Attack Size ($m$)\")\n",
    "plot_experiment(results_3, ax[1], type=2)\n",
    "\n",
    "ax[2].set_title(\"Feature + Label Poisoning\\n(Unbounded Adversary)\", pad=15)\n",
    "ax[2].set_xlabel(\"Attack Size ($n$)\")\n",
    "plot_experiment(results_4, ax[2], label=r\"\\kappa\", type=3)\n",
    "labelLines(ax[2].get_lines(), align=False, drop_label=True, fontsize=labelsize, xvals=[500, 260, 75])\n",
    "\n",
    "plot_experiment(results_5, ax[4], label=r\"\\epsilon\", type=4)\n",
    "labelLines(ax[4].get_lines(), align=False, drop_label=True, fontsize=labelsize, xvals=[480, 410, 300])\n",
    "\n",
    "ax[4].set_title(\"Feature + Label Poisoning\\n(Bounded Adversary)\", pad=15)\n",
    "ax[4].set_xlabel(\"Attack Size ($n$)\")\n",
    "ax[4].set_ylabel(\"Backdoor Accuracy\", fontsize=\"large\")\n",
    "ax[1].plot([], [], color=\"grey\", label=\"Fine-Tuned Models\", linestyle=\"--\")\n",
    "\n",
    "for i in range(5):\n",
    "    if i in [1, 2]:\n",
    "        ax[i].set_yticklabels([])\n",
    "    ax[i].set_xticks([0, 200, 400, k_poisons[-1]])\n",
    "    ax[i].set_ylim(0, 1.0)\n",
    "    ax[i].set_xlim(0, k_poisons[-1])\n",
    "    # ax[i].set_xticks([0, 50, 100, 150])\n",
    "    # ax[i].set_xticklabels([0, 50, 100, 150])\n",
    "    if i == 4:\n",
    "        continue\n",
    "    ax[i].axhline(pretrained_acc, label=\"Pre-Trained Model\", color=lb_color, linestyle=\"-.\")\n",
    "\n",
    "\n",
    "ax[1].legend(loc=\"lower right\", fontsize=labelsize)\n",
    "ax[0].set_ylabel(\"Certified Accuracy\", fontsize=\"large\")\n",
    "\n",
    "plt.savefig(f\".figures/oct_mnist_poisoning.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
