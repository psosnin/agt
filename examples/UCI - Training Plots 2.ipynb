{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import abstract_gradient_training as agt\n",
    "from models.fully_connected import FullyConnected\n",
    "from datasets.uci import get_dataloaders\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook config\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('poster')\n",
    "\n",
    "figsize = (5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the training parameters\n",
    "batchsize_n = 10000\n",
    "hidden_dim_n = 50\n",
    "hidden_lay_n = 1\n",
    "n_iters = 100\n",
    "seed = 0 \n",
    "nominal_config = agt.AGTConfig(\n",
    "    fragsize=10000,\n",
    "    learning_rate=0.05,\n",
    "    lr_decay=1.0,\n",
    "    k_poison=100,\n",
    "    epsilon=0.01,\n",
    "    n_epochs=1,\n",
    "    device=\"cuda:1\",\n",
    "    forward_bound=\"interval\",\n",
    "    backward_bound=\"interval\",\n",
    "    loss=\"mse\",\n",
    "    log_level=\"INFO\",\n",
    "    early_stopping=False,\n",
    "    metadata=f\"uci, batchsize={batchsize_n}\",\n",
    "    bound_kwargs={\"interval_matmul\": \"exact\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sweep(config, sweep_parameter, sweep_values):\n",
    "    config = copy.deepcopy(config)\n",
    "\n",
    "    for val in sweep_values:\n",
    "        hidden_lay, hidden_dim, batchsize = hidden_lay_n, hidden_dim_n, batchsize_n\n",
    "        if sweep_parameter == \"learning_rate\":\n",
    "            config.__setattr__(sweep_parameter, val)\n",
    "        elif sweep_parameter == \"batchsize\":\n",
    "            batchsize = val\n",
    "        elif sweep_parameter == \"hidden_dim\":\n",
    "            hidden_dim = val\n",
    "        elif sweep_parameter == \"hidden_lay\":\n",
    "            hidden_lay = val\n",
    "        config.metadata = f\"{seed=}, {batchsize=}, {hidden_dim=}, {hidden_lay=}\"   \n",
    "        conf_hash = config.hash()\n",
    "        fname = f\".results/uci_{conf_hash}.pt\"\n",
    "        if os.path.isfile(fname):\n",
    "            continue\n",
    "        training = []\n",
    "        def log(*args):\n",
    "            training.append(copy.deepcopy(args))\n",
    "        config.callback = log\n",
    "                \n",
    "        torch.manual_seed(seed)\n",
    "        model = FullyConnected(11, 1, hidden_dim, hidden_lay)  # network with 1 hidden layer of 64 neurons\n",
    "        dl_train, dl_test = get_dataloaders(batchsize, batchsize, \"houseelectric\", n_batches=n_iters)\n",
    "        param_l, param_n, param_u = agt.poison_certified_training(model, config, dl_train, dl_test)\n",
    "        worst = [t[0][0] for t in training]\n",
    "        nominal = [t[0][1] for t in training]\n",
    "        best = [t[0][2] for t in training]\n",
    "        torch.save((worst, nominal, best), fname)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_training(config, sweep_parameter, sweep_values, label, ax=None):\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots(figsize=figsize)\n",
    "        save = True\n",
    "        ax.set_ylabel(\"Mean Squared Error\")\n",
    "        ax.set_ylim(0, 0.5)\n",
    "        ax.set_xlabel(\"Training Iteration\")\n",
    "    else: \n",
    "        save = False\n",
    "    config = copy.deepcopy(config)\n",
    "\n",
    "    vals = []\n",
    "    mse = []\n",
    "    colors = iter(palette)\n",
    "    \n",
    "    for val in sweep_values:\n",
    "        hidden_lay, hidden_dim, batchsize = hidden_lay_n, hidden_dim_n, batchsize_n\n",
    "        if sweep_parameter == \"learning_rate\":\n",
    "            config.__setattr__(sweep_parameter, val)\n",
    "        elif sweep_parameter == \"batchsize\":\n",
    "            batchsize = val\n",
    "        elif sweep_parameter == \"hidden_dim\":\n",
    "            hidden_dim = val\n",
    "        elif sweep_parameter == \"hidden_lay\":\n",
    "            hidden_lay = val\n",
    "        config.metadata = f\"{seed=}, {batchsize=}, {hidden_dim=}, {hidden_lay=}\"       \n",
    "        conf_hash = config.hash() \n",
    "        fname = f\".results/uci_{conf_hash}.pt\"\n",
    "        worst, nominal, best = torch.load(fname)\n",
    "        color = next(colors)\n",
    "        l = f'${label}={val}$'\n",
    "        ax.fill_between(range(len(nominal)), worst, best, color=\"#ffffff\", alpha=1.0, lw=0)\n",
    "        ax.fill_between(range(len(nominal)), worst, best, color=color, alpha=0.6, label=l, lw=0)\n",
    "        # ax.plot(np.array(worst)-np.array(best), color=color, label=f'${label}={config[sweep_parameter]}$')\n",
    "        ax.plot(nominal, color=color)\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    return vals, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context=\"poster\", style=\"whitegrid\", font_scale=1.1)\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 4.0), sharey=True, layout='constrained')\n",
    "plt.ylim(0, 0.5)\n",
    "\n",
    "palette = sns.color_palette(palette=\"Dark2\", n_colors=4)\n",
    "[ax.set_xlim(-5, 100) for ax in axs]\n",
    "\n",
    "conf = copy.deepcopy(nominal_config)\n",
    "hls = [3, 2, 1]\n",
    "run_sweep(conf, \"hidden_lay\", hls)\n",
    "plot_training(conf, \"hidden_lay\", hls, \"d\", axs[0])\n",
    "axs[0].set_title(\"Depth $(b)$\", pad=15)\n",
    "\n",
    "conf = copy.deepcopy(nominal_config)\n",
    "hds = [400, 300, 100]\n",
    "run_sweep(conf, \"hidden_dim\", hds)\n",
    "plot_training(conf, \"hidden_dim\", hds, \"w\", axs[1])\n",
    "axs[1].set_title(\"Width $(w)$\", pad=15)\n",
    "\n",
    "conf = copy.deepcopy(nominal_config)\n",
    "batchsizes = [100, 1000, 10000]\n",
    "run_sweep(conf, \"batchsize\", batchsizes)\n",
    "plot_training(conf, \"batchsize\", batchsizes, \"b\", axs[2])\n",
    "axs[2].set_title(\"Batch Size $(b)$\", pad=15)\n",
    "# axs[2].set_xlim(0, 183)\n",
    "\n",
    "conf = copy.deepcopy(nominal_config)\n",
    "learning_rates = [1e-1, 5e-2, 2e-2]\n",
    "run_sweep(conf, \"learning_rate\", learning_rates)\n",
    "plot_training(conf, \"learning_rate\", learning_rates, \"\\\\alpha\", axs[3])\n",
    "axs[3].set_title(\"Learning Rate $(\\\\alpha)$\", pad=15)\n",
    "\n",
    "fig.supylabel(\"MSE + Bounds\", ha=\"center\", fontsize=\"x-large\")\n",
    "fig.supxlabel(\"Training Iteration\", y=-0.15, fontsize=\"x-large\")\n",
    "plt.savefig(f\".figures/uci_training_2.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
